{"doctype":"markdown","bookId":"book:2pLIiVrD5","createdAt":1693720848899,"updatedAt":1694611750273,"status":"none","share":"private","numOfTasks":0,"numOfCheckedTasks":0,"title":"Notes","body":"## Types of Bias\n\nIn statistics, a bias is a difference between the parameter predicted from a survey from the true value of the parameter in the population. Two broad categories of statistical bias include selection bias and response bias.\n\n> **_Selection bias_** exists when the sampling units selected from a population are not representative of the entire population, and are instead biased toward certain subsets of the population. A population should be surveyed in such a way to minimize sampling bias. Several types of selection bias follow.\n\n> **_ndercoverage_** occurs when certain members of a population are inadequately represented in a sample.\n\n> **_Nonresponse bias_** occurs when a sample is biased toward members of a population that participate in a survey.\n\n> **_Voluntary response bias_** occurs when a sample is biased toward members that self-select for participation in a survey.\n\n> **_Response bias_** can result if the responses of survey participants are affected by how a question is asked or the behaviors or attitudes of the participant. Several types of response bias follow.\n\n> **_Acquiescence bias_** occurs when respondents tend to agree with a statement in a survey.\n\n> **_Extreme responding_** occurs when respondents tend to select the most extreme options available.\n\n> **_Social desirability bias_** occurs when respondents tend to answer questions in a way that is socially accepted by others. In other words, a social desirability bias exists when respondents over-report \"good\" behaviors or under-report \"bad\" behaviors.\n\n## Sampling methods\n\nDifferent sampling methods can help mitigate certain types of statistical bias.\n\n> In **_simple random sampling_**, a sample is constructed by random selection from the population. Mathematically, simple random sampling is a sampling method in which all possible samples consisting of\n> units selected from a population of\n> units are equally likely.\n\n> In **_systematic sampling_**, every\n> th unit from a population of\n> units is selected to be in a sample.\n\n> In **_stratified sampling_**, the population is first divided into groups, or strata, depending on some characteristic. Next, samples within each stratum are randomly selected in a proportional manner.\n\n> In **_cluster sampling_**, the population is first divided into groups, or clusters, depending on some characteristic. Next, the sample is constructed by randomly selecting one or more clusters.\n\n> In **_convenience sampling_**, units are drawn from a subset of the population that is readily available.\n\n---\n\n# Variability\n\n**Variability** is the difference between values in a dataset and the center of the dataset. A measure of center alone does not indicate the extent of variability. Ex: the data set , , , and and the data set , , , and both have a mean of and a median of . However, the values in the first dataset have a larger variability. Two common measures of variability are variance and standard deviation. **Variance**, is the average of the square difference from the mean. **Standard Deviation** is the square root of the variance. By definition, the variance is the square of the standard deviation.\n\n---\n\nThe formula for variance and standard deviation depends on whether the dataset contains the whole population or or a subset of the population. The sample standard deviation is denoted by , while the population standard deviation is denoted by . The formulas are given below.\n\n![clipboard.png](inkdrop://file:LksSfvS4D)\n\n**n** is the number of data values, **A^1, A^2...A^n** are the n data values, **X** is the sample mean, and p is the population mean.\n\n| A^n | X(median) | A^n - X | (A^n - X)^2 |\n| --- | --------- | ------- | ----------- |\n| a   | x         | a-x     | (a-x)^2     |\n| dis |           |         |             |\n\n---\n\n## MAD\n\n**Mean absolute deviation (MAD** is the mean of the absolute difference between each value and the mean of the values. The MAD uses the absolute value instead of the square root of a sum of squares to avoid negative distances. The formula for the MAD is given below.\n\n![clipboard.png](inkdrop://file:FzNHl4919)\n<span style=\"color:red \">Remember to use the Absolute Value of each pair.</span>\n\n---\n\n## Events\n\nA subset of the sample space is called an event. Ex: For a die roll, the event is rolling an even number. The event is a subset of the sample space .\n\nA **compound event** is a subset of the sample space consisting of **more than one outcome**. Ex: The event is a compound event since rolling an even number consists of three outcomes.\nEvents\n\nA **simple event** is a subset with a **single outcome**. Ex: The event is rolling a on the die. Thus, is a simple event because contains only one outcome.\n\n---\n\n## Probability\n\n**Probability** is a measure of how likely an event is to occur. The probability of an event E is denoted P(E), and is the sum of the probabilities of each outcome in the event.\n\nOne definition of probability is the number of desired outcomes divided by the total number of outcomes in the sample space, assuming that all outcomes are equally likely. Ex: If a (fair) coin is flipped, the probability that the coin turns up heads is desired outcome of heads divided by outcomes in the sample space (heads and tails), or .\n\nHowever, the size of the sample space often cannot be counted or determined in a practical way, or the different outcomes are not equally likely. Thus, another definition of probability is the relative frequency of the desired outcome, or the proportion of times the outcome will occur when an experiment is repeated an infinite number of times. Ex: If a coin is flipped many times, the frequency of heads will approach over time. Thus, the probability of heads is . Ex: If the frequency of red hair in a population is , and the experiment of selecting a random person from the population is performed many times, the probability that a person with red hair is selected will approach .\n\n---\n\n## Union, intersection, and complement\n\nSeveral set operations are used frequently in probability.\n\n![clipboard.png](inkdrop://file:Cl3v74JVy)\n![clipboard.png](inkdrop://file:OZs1T4-Df)\n\n---\n\n![clipboard.png](inkdrop://file:iyQu2qj7g)\n![clipboard.png](inkdrop://file:EFylCo8rV)\n\n---\n\n## <span style=\"color:lightgreen\">The axioms of probability</span>\n\n**Probability** has three fundamental **properties**, or **axioms**.\n\n![clipboard.png](inkdrop://file:Qjewla0j3)\n\n---\n\n## <span style=\"color:lightgreen\">The complement rule </span>\n\nThe **axioms** of probability have **two important consequences**, which are the **complement rule** and the **addition rule** of probability. The complement rule relates the probability of an event to the probability of the complement of the event.\n\n---\n\n## <span style=\"color:lightgreen\">Independent events </span>\n\nTwo events are **independent** if the probability of one event does not affect the probability of the other. Ex: A nickel and a dime are flipped. Whether the nickel comes up heads or tails is not affected by whether the dime comes up heads or tails. Thus, flipping the nickel and flipping the dime are independent events.\n\n## <span style=\"color:lightgreen\">The multiplication rule </span>\n\nThe **multiplication rule** gives the probability of independent events happening together.\n\n![clipboard.png](inkdrop://file:d5FCqCp32)\nIf doing Union, If **P(AnB)** is known, **P(AuB)** would be calculated as \"**P(A)+P(B)- P(AnB) = P(AuB)**\"\n\n---\n\n## <span style=\"color:lightgreen\">The Generalized multiplication rule </span>\n\nThe **multiplication rule** can also be generalized to more than independent events. Given independent events ,\n\n## <span style=\"color:lightgreen\"> The probability mass function of a discrete probability distribution </span>\n\nRandom variables have many powerful uses in modeling real world situations. A probability mass function captures useful information about a discrete random variable. A <span style='color:green'>**_probability mass function (pmf)</span>_** assigns the probability that a discrete random variable is exactly equal to some value (typically depicted as a table, plot, or equation). The notation <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>p</mi>\n<mo stretchy=\"false\">(</mo>\n<mi>X</mi>\n<mo>=</mo>\n<mi>x</mi>\n<mo stretchy=\"false\">)</mo>\n</math>\nor\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>p</mi>\n<mo stretchy=\"false\">(</mo>\n<mi>x</mi>\n<mo stretchy=\"false\">)</mo>\n</math>\nis typically used for the pmf of <math \nxmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>X</mi></math>\n. The probabilities assigned in a pmf are between <math \nxmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>0</mi></math>\nand <math \nxmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>1</mi></math>, and the total probability must sum to <math \nxmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>1</mi></math>.\n\n---\n\n## <span style=\"color:lightgreen\"> Calculation of PMF </span>\n\n### <span style=\"color:orange\">Example:</span>\n\nThe pmf of <math \nxmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>W</mi></math>\nis <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi> <mo stretchy=\"false\">(</mo> <mi>W</mi> <mo>=</mo> <mn>0</mn> <mo stretchy=\"false\">)</mo> <mo>=</mo> <mn>0.02</mn></math>, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi> <mo stretchy=\"false\">(</mo> <mi>W</mi> <mo>=</mo> <mn>1</mn> <mo stretchy=\"false\">)</mo> <mo>=</mo> <mn>0.27</mn></math>, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi> <mo stretchy=\"false\">(</mo> <mi>W</mi> <mo>=</mo> <mn>2</mn> <mo stretchy=\"false\">)</mo> <mo>=</mo> <mn>0.33</mn></math>, and<math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi> <mo stretchy=\"false\">(</mo> <mi>W</mi> <mo>=</mo> <mn>3</mn> <mo stretchy=\"false\">)</mo> <mo>=</mo> <mn>0.38</mn></math>.\n\n---\n\n## <span style=\"color:lightgreen\"> The cumulative distribution function of a probability distribution</span>\n\n> Another function used to describe the probabilities for all possible outcomes of a random variable is a cumulative distribution function. The **_<span style='color:lightblue'>cumulative distribution function (cdf)</span>_** of a discrete random variable is the probability that for any number <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi></math>, the observed value of the random variable will be at most\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi></math> or <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>p</mi> <mo stretchy=\"false\">(</mo> > <mi>X</mi> <mo>&#x2264;<!-- ≤ --></mo> <mi>x</mi> <mo stretchy=\"false\">)</mo></math>\n> . Ex: When a fair die is rolled and the value facing up recorded, the cdf describes the probability of getting less than or equal to any value\n> such that the probability\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>X</mi> </math> is less than or equal to <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>3</mi></math>, that is, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi><mo stretchy=\"false\">(</mo> <mi>X</mi> <mo>&#x2264;<!-- ≤ --></mo> <mi>3</mi> <mo stretchy=\"false\">)</mo> <mi>=</mi> <mi>p</mi><mo stretchy=\"false\">(</mo> <mi>1</mi> <mo stretchy=\"false\">)</mo> <mi>+</mi> <mi>p</mi><mo stretchy=\"false\">(</mo> <mi>2</mi> <mo stretchy=\"false\">)</mo> <mi>+</mi> <mi>p</mi><mo stretchy=\"false\">(</mo> <mi>3</mi> <mo stretchy=\"false\">)</mo> </math>\n> . The notation\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>F</mi><mo stretchy=\"false\">(</m> <mi>x</mi> <mo stretchy=\"false\">)</mo> > </math>\n> is typically used for the cdf of <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math>. Ex: <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>F</mi> > <mo stretchy=\"false\">(</mo> > <mn>3</mn> > <mo stretchy=\"false\">)</mo> > <mo>=</mo> > <mi>p</mi> > <mo stretchy=\"false\">(</mo> > <mi>X</mi> > <mo>&#x2264;<!-- ≤ --></mo> > <mn>3</mn> > <mo stretchy=\"false\">)</mo> > <mo>=</mo> > <mfrac> > <mn>1</mn> > <mi>/</mi> > <mn>2</mn> > </mfrac> > </math>\n> is read \"the probability <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math>\n> is less than or equal to <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>3</mi></math>\n> is one half\". The cdf always starts at <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>0</mi></math>\n> and ends at <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>1</mi></math>\n> and never decreases as the value of <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math> increases.\n\n## <span style=\"color:lightgreen\">Mean or expected value of a discrete random variable</span>\n\n> The <span style='color:lightblue'>**mean**</span> or <span style='color:lightblue'>**expected value**</span> > <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>&#x03BC;<!-- μ --></mi> > </math>\n> of a discrete random variable\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>X</mi> > </math>\n> is the sum of the possible values of\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>X</mi> > </math>\n> multiplied by the probability of the value. The mean is calculated as follows.\n\n  <center><span style='color:red'>\n    <math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n    <mi>&#x03BC;<!-- μ --></mi>\n    <mo>=</mo>\n    <mi>E</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>X</mi>\n    <mo stretchy=\"false\">)</mo>\n    <mo>=</mo>\n    <mo>&#x2211;<!-- ∑ --></mo>\n    <mo stretchy=\"false\">(</mo>\n    <mi>x</mi>\n    <mo>&#x22C5;<!-- ⋅ --></mo>\n    <mi>p</mi>\n    <mo stretchy=\"false\">(</mo>\n    <mi>x</mi>\n    <mo stretchy=\"false\">)</mo>\n    <mo stretchy=\"false\">)</mo>\n  </math></span></center>\n  \n  \n> ![clipboard.png](inkdrop://file:aHH4nCv6m)\n\n## <span style=\"color:orange\">Practice</span>\n\n> Python-Practice 2.2.1: <span style=\"color:yellow\"> **_Mean, variance, and standard deviation_** </span> of a discrete random variable.\n> To find the mean, variance, and standard deviation of a discrete random variable, the rv_discrete class must be imported from the scipy.stats library. Next, a list containing the outcomes in a sample space and a list containing the probabilities of each outcome are defined. The outcome and probability lists are then linked.\n\n```\nfrom scipy.stats import rv_discrete\n\n# Defines a list containing the outcomes in the sample space\nx = [0,1,2,3,4,5,6]\n\n# Defines a list containing the probabilities for each outcome\np = [0.1,0.2,0.3,0.1,0.1,0.0,0.2]\n\n# Links the values in x to the probabilities in p\ndiscvar = rv_discrete(values=(x,p))\n```\n\nTo find the **mean**, the .mean() method is used.\n\n```\n# Returns the mean of the discrete random variable\nprint(discvar.mean())\n```\n\n<center><span style='color:yellow'> returns 2.7</span> </center>\n\nTo find the variance, the .var() method is used.\n\n```\n# Returns the variance of the discrete random variable\n\nprint(discvar.var())\n```\n\n<center><span style='color:yellow'> returns 3.81</span> </center>\n\nTo find the standard deviation, the .std() method is used.\n\n```\n# Returns the standard deviation of the discrete random variable\n\nprint(discvar.std())\n```\n\n<center><span style='color:yellow'> returns 1.95192212959</span> </center>\n\n## <span style=\"color:lightgreen\"> The probability density function of a continuous random variable</span>\n\n> A <span style=\"color:lightblue\">**probability density function (pdf)**</span> describes the relative likelihood of all values for a continuous random variable. Ex: The amount of time for Casey to do his chores is a random variable <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math>, where all values between 1 hour and 2 hours are equally likely. The notation <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>F</mo><mo>(</mo><mi>x</mi><mo>)</mo> </math> is typically used for the pdf. For Casey's chores, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>F</mo><mo>(</mo><mi>x</mi><mo>)</mo> <mo>=</mo> <mi>1</mi></math> for all values of <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi></math> between 1 and 2 and 0 everywhere else.\n\n![clipboard.png](inkdrop://file:njg1oVU1Q)\n\n## <span style=\"color:lightgreen\">The cumulative distribution function of a continuous random variable</span>\n\n> A <span style=\"color:lightblue\">**cumulative distribution function (cdf)**</span> of a continuous random variable is the probability that for any number <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>x</mi></math>, the observed value of the random variable will be at most <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>x</mi></math> or <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>p</mi> <mo stretchy=\"false\">(</mo> <mi>X</mi> <mo>&#x2264;<!-- ≤ --></mo> <mi>x</mi> <mo stretchy=\"false\">)</mo></math>. Ex: When Casey does housework, the cdf describes the probability of Casey finishing in time less than or equal to any value <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>x</mi></math> such that the probability <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mo>X</mo> </math> is less than or equal to <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>1.5</mi></math>. The notation <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>F</mi> <mo stretchy=\"false\">(</mo> <mi>x</mi> <mo stretchy=\"false\">)</mo></math> is typically used for the cdf of <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>X</mi></math>, in contrast to lower-case <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>1.5</mi></math> for the pdf. Ex: <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>F</mi> > <mo stretchy=\"false\">(</mo> > <mn>1.5</mn> > <mo stretchy=\"false\">)</mo> > <mo>=</mo> > <mi>P</mi> > <mo stretchy=\"false\">(</mo> > <mi>X</mi> > <mo>&#x2264;<!-- ≤ --></mo> > <mn>1.5</mn> > <mo stretchy=\"false\">)</mo> > </math>\n> is read \"the probability\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>X</mi></math> is less than or equal to <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>1.5</mi></math>\". As with discrete random variables, the cdf always starts at 0 and ends at 1 and never decreases as the value of\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>X</mi> > </math> increases. The cdf may approach the limits of 0 and 1 in cases where the possible values of\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>x</mi> > </math> are infinite.\n\n---\n\n## <span style=\"color:lightgreen\"> Mean, variance, and standard deviation of a continuous random variable</span>\n\nIn a previous section, the mean, variance, and standard deviation for a discrete random variable were defined. The interpretation of the three measures is similar for continuous random variables.\n\nThe mean\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>&#x03BC;<!-- μ --></mi>\n</math>\nor expected value\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>E</mi>\n<mo stretchy=\"false\">(</mo>\n<mi>X</mi>\n<mo stretchy=\"false\">)</mo>\n</math>\nof a continuous random variable\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>X</mi>\n</math>\nis a measure of the center of the distribution. The mean is a weighted average of the possible values of the random variable, with the pdf providing the weights. Graphically, the mean is where a pivot is placed so that the pdf balances.\nThe variance\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<msup>\n<mi>&#x03C3;<!-- σ --></mi>\n<mn>2</mn>\n</msup>\n</math>\nof a continuous random variable\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>X</mi>\n</math>\nis a measure of the spread of a distribution. The variance, like the mean, is a weighted average. The variance averages the squared distance of each possible value of\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>X</mi>\n</math>\nfrom the mean, with weights provided by the pdf.\nThe standard deviation\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<msup>\n<mi>&#x03C3;<!-- σ --></mi>\n</msup>\n</math>\nis another measure of the spread of the distribution. The standard deviation is the square root of the variance,\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>&#x03C3;<!-- σ --></mi>\n<mo>=</mo>\n<msqrt>\n<msup>\n<mi>SqR</mi>\n<mo stretchy=\"false\">(</mo>\n<mi>&#x03C3;<!-- σ --></mi>\n<mn>2</mn>\n<mo stretchy=\"false\">)</mo>\n</msup>\n</msqrt>\n</math>\n.\nIntegral calculus is required to compute the three quantities in the case of continuous random variables. The details are not discussed in this material.\n\n---\n\n## <span style=\"color:lightgreen\">Normal distribution</span>\n\nThe **normal distribution** is a continuous probability distribution characterized by a bell-shaped probability distribution function and is symmetric around the mean\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<mi>&#x03BC;<!-- μ --></mi>\n</math>\n. The normal distribution is also referred to as the Gaussian distribution. The normal distribution is pervasive because the distribution is a model for quantities that are computed as sums (totals) or averages. Often data is summarized using either the total or average. The normal distribution also occurs in many settings, including exam scores and heights or other physical measurements.\n\n### <span style='color:yellow'> Empirical Rule</span>\n\n> Unimodal and symmetric distributions, such as the normal distribution, follow a definite pattern useful for obtaining probabilities and interpreting outcomes. A **unimodal distribution** is a distribution with exactly one mode. In such distributions, the mean, median, and mode are equal.\n\n> The **empirical rule** states that for any unimodal and symmetric distribution: (1) 68% of the data fall within one standard deviation of the mean, (2) 95% of the data fall within two standard deviations of the mean, and (3) 99.7% of the data fall within three standard deviations of the mean. Mathematically,\n> ![clipboard.png](inkdrop://file:OtlgjBpkD) > ![clipboard.png](inkdrop://file:737xwxt3m)\n\n#### <span style='color:orange'> Practice: </span>\n\n![clipboard.png](inkdrop://file:baAkP7aZe)\n![clipboard.png](inkdrop://file:1a-pOY4pF)\n\n---\n\n## <span style='color:lightgreen'>Z-scores </span>\n\n> A <span style='color:yellow'>**z-score**</span> is a signed value that indicates the number of standard deviations a quantity is from the mean. A positive z-score indicates that the quantity is above the mean and a negative z-score indicates that the quantity is below the mean. A z-score with high absolute value implies that the quantity is farther from the mean, and thus more unusual.\n\n> The z-score is given by ![clipboard.png](inkdrop://file:ELshRPwar)\n> where x is the raw score,\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>&#x03BC;<!-- μ --></mi> > </math>\n> is the mean, and\n> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> > <mi>&#x03BC;<!-- μ --></mi> > </math>\n> is the standard deviation.\n> z-scores are particularly important for determining whether a data point is an outlier and for comparing quantities from different unimodal, symmetric distributions.\n\n### <span style='color:orange'>EPS</span>\n\n![clipboard.png](inkdrop://file:TY2iP1Nen)\n\n> #### Analysis\n>\n> To determine whether the eps of Walmart compared to the other companies is unusual, the sample mean and sample standard deviation should be computed. Using Python, these quantities can be calculated as follows.\n\n```\nimport pandas as pd\n\n# Create a DataFrame containing the eps data\nearnings_surprise = pd.DataFrame([11.36, 7.89, 1.96, 0, -3.12, -9.52])\nprint(earnings_surprise.mean())\nprint(earnings_surprise.std())\n```\n\n![clipboard.png](inkdrop://file:zHKhIWMLN)\n\n# <span style='color:violet'>Python</span>\n\n### Python-Function 2.4.1: norm.cdf() and norm.sf()\n\n> The <span style='color:yellow'>**norm.cdf()**</span> and <span style='color:yellow'>**norm.sf()**</span> functions are used to find probabilities related to the normal distribution. The scipy.stats library must be imported to use these functions.\n\n> <span style='color:yellow'>**norm.cdf(z, mean, sd)**</span> returns the probability of z being less or equal to than the critical value z for a normal distribution with the specified mean and standard deviation.\n>\n> ```\n> import scipy.stats as st\n>\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(z <= -0.25)?\n>\n> print(st.norm.cdf(-0.25, 0, 1))\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(z <= 1.5)?\n> print(st.norm.cdf(1.5, 0, 1))\n> ```\n\n> <span style='color:yellow'>\\*\\*norm.sf(z, mean, sd)</span> returns the probability of z being greater than or equal to the critical value z for a normal distribution with the specified mean and standard deviation.\n>\n> ```\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(z >= -0.25)?\n> print(st.norm.sf(-0.25, 0, 1))\n>\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(z >= 1.5)?\n> print(st.norm.sf(1.5, 0, 1))\n> ```\n\n> To find the probability between two critical values, the difference between the two probabilities is calculated.\n>\n> ```# For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(-0.25 <= z <= 1.5)?\n> print(st.norm.cdf(1.5, 0, 1) - st.norm.cdf(-0.25, 0, 1))\n>\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is P(1.5 <= z <= 2.85)?\n> print(st.norm.cdf(2.85, 0, 1) - st.norm.cdf(1.5, 0, 1))\n> ```\n\n> Both <span style='color:yellow'>norm.cdf()</span> and <span style='color:yellow'>norm.sf()</span> can also be used for non-standard normal distributions, that is, when the mean is not 0 or the standard deviation is not 1.\n>\n> ```\n> # For a normal distribution, if the mean is 55 and\n> # the standard deviation is 7.5, what is P(x <= 62)?\n> print(st.norm.cdf(62, 55, 7.5))\n>\n> # For a normal distribution, if the mean is 55 and\n> # the standard deviation is 7.5, what is P(x >= 51)?\n> print(st.norm.sf(51, 55, 7.5))\n>\n> # For a normal distribution, if the mean is 55 and\n> # the standard deviation is 7.5, what is P(49 <= x <= 60)?\n> print(st.norm.cdf(60, 55, 7.5) - st.norm.cdf(49, 55, 7.5))\n> ```\n\n## <span style='color:orange'>EXAMPLES:</span>\n\n> The GRE (Graduate Record Exam) scores for both verbal and quantitative reasoning are approximately normally distributed and scaled to have a mean of 150 and 8.75 as the standard deviation.\n> ![clipboard.png](inkdrop://file:UfV4HDrlH)\n\n> 1. What is the probability of scoring between 165 and 170?\n>\n> - Less than the probability x of a score between 150 and 155.\n>\n> <span style='color:orange'>**_Analysis_**</span>  \n> <span style='color:yellow'>**The normal distribution has higher density near the mean.**</span> Thus, for the same change in x of 5 points, the <span style='color:yellow'>**Interval furthest from the mean has the lowest probability.**</span> Using the Python command <span style='color:violet'>**st.norm.cdf (170, 150, 8.75) -st.norm.cdf (165, 150, 8.75)**</span> gives a probability of <span style='color:white'>**0.0321**</span>, which is less than the probability of a score between 150 and 155 found using the command <span style='color:violet'>st.norm.cdf (155, 150, 8.75) - st.norm. cdf (150, 150, 8.75)</span>, which gives <span style='color:white'>0.2161</span>.\n\n---\n\n## Python-Function 2.4.2: norm.ppf() and norm.isf().\n\n> The <span style='color:yellow'>**_norm.ppf()_**</span> and <span style='color:yellow'>**_norm.isf()_**</span> functions are used to convert percentiles to z-scores. The scipy.stats library must be imported to use these functions.\n\n> <span style='color:yellow'>**_norm.ppf(p, mean, sd)_**</span> returns the critical z-score for which the probability of _z_ being below that z-score is p, for a normal distribution with the specified mean and standard deviation.\n>\n> ```\n> import scipy.stats as st\n>\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is z* if P(z < z*) = 0.135?\n> print(st.norm.ppf(0.135, 0, 1))\n> ```\n\n> <span style='color:yellow'>**_norm.isf(p, mean, sd)_**</span> returns the critical z-score for which the probability of z being above that z-score is p, for a normal distribution with the specified mean and standard deviation.\n>\n> ```\n> # For a normal distribution, if the mean is 0 and\n> # the standard deviation is 1, what is z* if P(z > z*) = 0.405?\n> print(st.norm.isf(0.405, 0, 1))\n> ```\n\n> Both <span style='color:yellow'>**_norm.ppf()_**</span> and <span style='color:yellow'>**_norm.isf()_**</span> can also be used with non-standard normal distributions.\n>\n> ```\n> # For a normal distribution, if the mean is 55 and\n> # the standard deviation is 7.5, what is x* if P(x < x*) = 0.8247?\n> print(st.norm.ppf(0.8247, 55, 7.5))\n>\n> # For a normal distribution, if the mean is 55 and\n> # the standard deviation is 7.5, what is x* if P(x > x*) = 0.95?\n> print(st.norm.isf(0.95, 55, 7.5))\n> ```\n\n---\n\n## <span style='color:lightgreen'>Sampling distribution for sample means</span>\n\n> Often, statisticians look at the distribution of a test statistic, such as the sample mean. Suppose a sample of size **_n_** is taken from a population and the sample mean is computed. Repeating this process for multiple samples and creating a relative frequency plot of the obtained test statistic yields a sampling distribution.\n\n> The **_sampling distribution_** of the mean, denoted by <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mover> <mi>X</mi> <mo accent=\"false\">&#x00AF;<!-- ¯ --></mo> </mover></math>, is the distribution of sample means when taking random samples of the same size. The <span style='color:yellow'>**_mean of the sample means_**</span>, denoted by <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <msub> <mi>&#x03BC;<!-- μ --></mi> <mrow class=\"MJX-TeXAtom-ORD\"> <mover> <mi>X</mi> <mo accent=\"false\">&#x00AF;<!-- ¯ --></mo> </mover> </mrow> </msub></math>, is the population mean. That is, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <msub> <mi>&#x03BC;<!-- μ --></mi> <mrow class=\"MJX-TeXAtom-ORD\"> <mover> <mi>X</mi> <mo accent=\"false\">&#x00AF;<!-- ¯ --></mo> </mover> </mrow> </msub> <mo>=</mo> <mi>&#x03BC;<!-- μ --></mi></math>. The <span style='color:white'>standard error <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mo stretchy=\"false\">(</mo> <mi>S</mi> <mi>E</mi> <mo stretchy=\"false\">)</mo></math> </span>is the standard deviation of the sampling distribution, denoted by <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <msub> <mi>&#x03C3;<!-- σ --></mi> <mrow class=\"MJX-TeXAtom-ORD\"> <mover> <mi>X</mi> <mo accent=\"false\">&#x00AF;<!-- ¯ --></mo> </mover> </mrow> </msub></math>, when sampling with replacement. That is, <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <msub> <mi>&#x03C3;<!-- σ --></mi><mrow class=\"MJX-TeXAtom-ORD\"> <mover><mi>X</mi><mo accent=\"false\">&#x00AF;<!-- ¯ --></mo> </mover></mrow></msub><mo>=</mo><mfrac> <mi>&#x03C3;<!-- σ --></mi><msqrt><mi>n</mi> </msqrt> </mfrac> </math>. The standard deviation requires a correction factor when sampling without replacement. This correction factor is SqR((n-n)/(n-1)), where **_N_** is the population size.\n\n![clipboard.png](inkdrop://file:s4dC1kHdH)\n","tags":[],"_id":"note:JTyynbc8J","_rev":"167-b5751e0ba1362df9382e4590d9066c9d"}